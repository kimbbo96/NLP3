bigram embedding size =64
learning rate=0.005
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.07571346585343523, 0.07099519719570016, 0.07451331028983228, 0.08148402694257559]
val_acc=[0.9738717993717236, 0.9760698370817231, 0.9766334028307456, 0.9764824932536106]
loss=[0.1021206100110213, 0.03805692473212878, 0.029357196495930354, 0.024031722114284833]
acc=[0.9611440051714579, 0.9863591825358073, 0.9893723390897116, 0.9912168045107523]
score test:0.9240999387902732
bigram embedding size =32
learning rate=0.005
n_stacked=1
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.07886112758893925, 0.07380834003774131, 0.07748342174912767, 0.0790725304784373]
val_acc=[0.9724330795049139, 0.9747483943095493, 0.9751417907801542, 0.9753095473259885]
loss=[0.12258599017461141, 0.03781968008915583, 0.02932062389532725, 0.024008536899288495]
acc=[0.9530779468663534, 0.9865192364947001, 0.9895163969739278, 0.9913607803853353]
score test:0.9211153322777607
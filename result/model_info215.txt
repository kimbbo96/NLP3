bigram embedding size =128
learning rate=0.005
n_stacked=2
dropout_LSTM=0.4
batch size=256
rnn hidden size = 256
val_loss=[0.10875838842994623, 0.08080172935240548, 0.08137894854643392, 0.08100656049941438]
val_acc=[0.9619427521582982, 0.9727744557905091, 0.97322258188032, 0.9735118499616298]
loss=[0.21052126350323358, 0.04991034106810888, 0.03837772869626681, 0.03177797427495321]
acc=[0.9140657543373107, 0.9829536018689473, 0.9865696930567424, 0.9887831865310669]
score test:0.9155103424203641
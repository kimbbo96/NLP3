bigram embedding size =128
learning rate=0.03
n_stacked=1
dropout_LSTM=0.2
batch size=256
rnn hidden size = 256
val_loss=[0.39125461879696394, 1.1920930968545122e-07, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.8139324075895509, 0.7834935469796547, 0.7834935469796547, 0.7834935469796547]
loss=[0.42050254683176674, 0.32482745643615724, 1.1920930376163597e-07, 1.1920930376163597e-07]
acc=[0.8090484372965495, 0.8111802760950725, 0.8139350433286031, 0.8139350433286031]
score test:0.30981733196412403
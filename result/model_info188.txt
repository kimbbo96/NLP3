bigram embedding size =128
learning rate=0.03
n_stacked=2
dropout_LSTM=0.4
batch size=128
rnn hidden size = 64
val_loss=[0.09629281342624296, 0.09514528398965785, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9663669914998395, 0.966475209613597, 0.7834935469796547, 0.7834935469796547]
loss=[0.11816918865362804, 0.06343250869274139, 0.07827681481680612, 1.1920930695093071e-07]
acc=[0.9545546111742655, 0.9775147353426615, 0.8114182814915974, 0.7921658163833618]
score test:0.30981733196412403
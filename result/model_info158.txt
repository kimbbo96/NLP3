bigram embedding size =128
learning rate=0.04
n_stacked=2
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.10306853468957339, 0.09834250733421541, 0.10641306318227045, 0.11146820163118866]
val_acc=[0.9644944168247299, 0.9658656637050096, 0.9639229610595365, 0.9612207127251805]
loss=[0.1434120517985026, 0.061924572474956516, 0.06005265075206757, 0.060975850984255474]
acc=[0.9477792666117351, 0.9787600033950805, 0.9790015291086833, 0.9786063963890076]
score test:0.8759820114224433
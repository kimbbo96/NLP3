bigram embedding size =128
learning rate=0.03
n_stacked=1
dropout_LSTM=0.3
batch size=128
rnn hidden size = 256
val_loss=[0.10483028564577357, 0.11846489731858416, 0.11870550934200541]
val_acc=[0.9635732623267332, 0.9592999535759378, 0.9579610543081871]
loss=[0.13418745979865393, 0.07451378530422846, 0.07734175939480464]
acc=[0.9473884505208333, 0.9737571283276876, 0.9730023218218485]
score test:0.8656876482818278
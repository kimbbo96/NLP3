bigram embedding size =128
learning rate=0.005
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.07942599596707625, 0.07792677472607788, 0.07454462963963823, 0.0797794661143931]
val_acc=[0.9729123383826532, 0.9745049651076154, 0.975385717700696, 0.9741619801574166]
loss=[0.15068265063881875, 0.04143138314525286, 0.031350658343633014, 0.025588967988689742]
acc=[0.9367702028910319, 0.9852818656539917, 0.9885821105829875, 0.9906887509028117]
score test:0.9178575583895265
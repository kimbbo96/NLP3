bigram embedding size =32
learning rate=0.005
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[0.0795522718101806, 0.07385160166051594, 0.07527928044420652, 0.08705197798373165]
val_acc=[0.9724824521071102, 0.9761697768900717, 0.975283544634504, 0.9741317658889584]
loss=[0.09873143492182096, 0.03674598598440488, 0.027693735390901565, 0.022110063353379568]
acc=[0.9635040994135539, 0.9868092278035482, 0.9899841548919678, 0.9918826906267801]
score test:0.917923320905904
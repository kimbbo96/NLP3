bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.3
batch size=128
rnn hidden size = 64
val_loss=[0.07685464642066385, 0.07501461122292373, 0.07583421937906556, 0.08631992672142591]
val_acc=[0.9736418139908107, 0.9748728949320554, 0.9757277571705651, 0.9748466466852936]
loss=[0.10202319538354873, 0.03841028185884158, 0.029242099346319834, 0.02372211256245772]
acc=[0.9617815052477519, 0.9863110766537985, 0.9893951216189066, 0.991363507639567]
score test:0.919764671364471
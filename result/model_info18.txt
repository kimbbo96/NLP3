bigram embedding size =32
learning rate=0.04
n_stacked=2
dropout_LSTM=0.3
batch size=256
rnn hidden size = 64
val_loss=[0.09531259437622358, 0.09205590543686154, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9675336217140147, 0.9691635168048072, 0.7834935469796547, 0.7834935469796547]
loss=[0.11083784159024557, 0.05187416704018911, 0.133537971363074, 1.1920930376163597e-07]
acc=[0.9578281269836426, 0.9818468977610271, 0.8639917640113831, 0.8139350433286031]
score test:0.30981733196412403
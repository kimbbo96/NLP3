bigram embedding size =64
learning rate=0.03
n_stacked=2
dropout_LSTM=0.4
batch size=256
rnn hidden size = 64
val_loss=[0.09290213246897953, 0.08933229273610527, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9684982353990729, 0.9697960498856335, 0.7834935469796547, 0.7834935469796547]
loss=[0.13616908550421397, 0.052883012777169544, 0.10024767458399479, 1.1920930376163597e-07]
acc=[0.9464991110579173, 0.9815592141215006, 0.9187139174397786, 0.8139350433286031]
score test:0.30981733196412403
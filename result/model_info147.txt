bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.2
batch size=256
rnn hidden size = 256
val_loss=[0.09306237892869307, 0.0948420644235981, 0.09096094471982737, 0.1026419044829525]
val_acc=[0.9674402935277596, 0.9686723013146225, 0.9695461654081577, 0.9635079415833078]
loss=[0.13347968071142832, 0.04711351396004359, 0.04304567296624184, 0.04262945388197899]
acc=[0.9509995442326864, 0.9833683391888937, 0.9847023408444723, 0.9847957336362203]
score test:0.8833372959464997
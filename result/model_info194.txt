bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.07863160478830866, 0.07711470693746321, 0.07914695827633209, 0.08125466787299666]
val_acc=[0.9728922594148673, 0.9745750505221128, 0.9749766503627971, 0.9746190653143331]
loss=[0.11484117279450098, 0.03716454484144847, 0.028008774417241415, 0.02227491796751817]
acc=[0.9571463324419658, 0.9869342724927267, 0.9899131699244181, 0.9919259229914348]
score test:0.918788350929022
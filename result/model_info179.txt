bigram embedding size =128
learning rate=0.03
n_stacked=1
dropout_LSTM=0.4
batch size=256
rnn hidden size = 256
val_loss=[0.29394342993156874, 0.1817186720950112, 0.13290337722608098, 0.12247208305975286]
val_acc=[0.8799251410490657, 0.9386401255749282, 0.95392091364131, 0.9588635685438591]
loss=[0.3658282844734192, 0.18867052203178405, 0.10366482256889344, 0.07449956558465957]
acc=[0.8338892194302877, 0.9273835230318705, 0.9634586254183451, 0.9741053197733561]
score test:0.8685306124513736
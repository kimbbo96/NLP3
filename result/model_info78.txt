bigram embedding size =64
learning rate=0.04
n_stacked=1
dropout_LSTM=0.3
batch size=256
rnn hidden size = 64
val_loss=[0.08841253886466016, 0.09390258181121555, 0.09086684730655603]
val_acc=[0.9698117066116925, 0.9680221873746478, 0.9685147368987225]
loss=[0.08937208128372828, 0.04892598475535711, 0.047619174186388655]
acc=[0.9682775222524007, 0.9827107225735983, 0.9830825998878479]
score test:0.8989331296381544
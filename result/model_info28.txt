bigram embedding size =32
learning rate=0.03
n_stacked=1
dropout_LSTM=0.3
batch size=128
rnn hidden size = 64
val_loss=[0.08901204684224731, 0.09026725545624671, 0.09399931357467253]
val_acc=[0.9685361364199687, 0.9698174661913362, 0.967865784258113]
loss=[0.0852842468671004, 0.051213864195346834, 0.05074006357034047]
acc=[0.9700211294937133, 0.9818828603490194, 0.9820606267738342]
score test:0.8971120138000112
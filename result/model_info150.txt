bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.3
batch size=256
rnn hidden size = 64
val_loss=[0.09559845055418374, 0.09573259141849573, 0.09580682138778154]
val_acc=[0.966985904588932, 0.9672006874814002, 0.9674494253293903]
loss=[0.11205592141310373, 0.05412599532524745, 0.052503252422014875]
acc=[0.957753485066096, 0.980987616259257, 0.9816366848436991]
score test:0.8961812212605157
bigram embedding size =32
learning rate=0.03
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.09859709492874251, 0.19468079081131456, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9651158453355607, 0.9261659488181053, 0.7834935469796547, 0.7834935469796547]
loss=[0.11300472663720448, 0.1087112876367569, 0.14516891412099378, 1.1920930695093071e-07]
acc=[0.9583392655754089, 0.9600109107081095, 0.9062123000717163, 0.7921658163833618]
score test:0.30981733196412403
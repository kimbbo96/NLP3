bigram embedding size =128
learning rate=0.005
n_stacked=2
dropout_LSTM=0.3
batch size=128
rnn hidden size = 256
val_loss=[0.08056915776097853, 0.07574613111510774, 0.0778208351518521, 0.08818005887737825]
val_acc=[0.9726555220567995, 0.9740901800851336, 0.9746661755832494, 0.9741631499150905]
loss=[0.11120723109881084, 0.040361110759576165, 0.030242139147718748, 0.02512085340619087]
acc=[0.957600772190094, 0.9858004710197449, 0.9891467059453328, 0.9909494691467285]
score test:0.9179435555263278
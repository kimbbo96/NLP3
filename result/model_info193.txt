bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[0.07408353787105522, 0.07189677148528743, 0.0790608894005583, 0.08189202045522086]
val_acc=[0.9750181665177355, 0.9762377041142162, 0.9763027219444579, 0.9764669174101295]
loss=[0.08197665135939916, 0.03494437405228615, 0.026094135846296947, 0.020918422722617784]
acc=[0.9704169505437216, 0.9873830993588766, 0.9904620948092143, 0.9923748238309225]
score test:0.9247069774029877
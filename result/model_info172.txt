bigram embedding size =128
learning rate=0.03
n_stacked=1
dropout_LSTM=0.3
batch size=128
rnn hidden size = 64
val_loss=[0.09038124519282592, 0.10598846007873637, 0.10089126630725459]
val_acc=[0.968719473699244, 0.9653961571251474, 0.9649455434995851]
loss=[0.08543778672138849, 0.06186724756638209, 0.06068950269858042]
acc=[0.9693886916605632, 0.9782776181348165, 0.9787071358044942]
score test:0.8888664059773069
bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.07682020000766492, 0.0812877681593673, 0.0788902721456572]
val_acc=[0.9735287780772292, 0.9732339086130823, 0.9765016830416846]
loss=[0.08984517222166061, 0.03642032766540845, 0.028071273495952287]
acc=[0.9663117398007711, 0.9869744584019979, 0.9897679263814291]
score test:0.9250054380542388
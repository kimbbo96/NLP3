bigram embedding size =64
learning rate=0.03
n_stacked=2
dropout_LSTM=0.4
batch size=256
rnn hidden size = 256
val_loss=[0.3699876879509167, 0.3591804435009967, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.817608264491722, 0.8240646435786245, 0.7834935469796547, 0.7834935469796547]
loss=[0.4304320770994822, 0.35033523081461587, 0.3062325705273946, 1.1920930376163597e-07]
acc=[0.8086550408554077, 0.8220977371470134, 0.822047565313975, 0.8139350433286031]
score test:0.30981733196412403
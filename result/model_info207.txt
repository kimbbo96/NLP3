bigram embedding size =128
learning rate=0.005
n_stacked=2
dropout_LSTM=0.2
batch size=256
rnn hidden size = 256
val_loss=[0.08721906062372507, 0.07810567876121687, 0.08329140608035804, 0.08154015373562498]
val_acc=[0.9704015524582958, 0.9737447469831835, 0.9711238920292146, 0.9735250391082595]
loss=[0.1819225745598475, 0.039512818364302316, 0.030021261133352916, 0.023897180010080336]
acc=[0.9306239158566793, 0.9861147176806132, 0.9893978704071045, 0.9915403692436219]
score test:0.9153788173876093
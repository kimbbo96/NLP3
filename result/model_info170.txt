bigram embedding size =128
learning rate=0.03
n_stacked=1
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.08757631700411604, 0.09431100600376362, 0.0878978094081921]
val_acc=[0.9697180735298376, 0.9686078782092177, 0.9708364440702282]
loss=[0.08491902325550715, 0.042496333494186404, 0.03958322451313337]
acc=[0.9697222890663147, 0.9849830772209167, 0.9858371588452657]
score test:0.90702697780768
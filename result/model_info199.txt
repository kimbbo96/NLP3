bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.3
batch size=256
rnn hidden size = 256
val_loss=[0.0868358318332558, 0.0757005438704184, 0.0752805811735056, 0.08428329574625666]
val_acc=[0.9700292946229753, 0.9738173224444928, 0.975164394949598, 0.9746753639498201]
loss=[0.12360192298173904, 0.03538968001643816, 0.026802608655095102, 0.021048977749149003]
acc=[0.9534381406275432, 0.9873975053660075, 0.990341366151174, 0.9923555058797201]
score test:0.9189401105822006
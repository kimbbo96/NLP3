bigram embedding size =128
learning rate=0.03
n_stacked=2
dropout_LSTM=0.4
batch size=256
rnn hidden size = 64
val_loss=[0.08841190741556447, 0.09373715300187303, 0.08967109627509592]
val_acc=[0.9697648294749123, 0.9680396469099294, 0.9690995053811506]
loss=[0.12365124787330628, 0.050414228253364564, 0.04751369369983673]
acc=[0.9528600881195068, 0.9821736476961772, 0.9831348375574748]
score test:0.9008554185784168
bigram embedding size =32
learning rate=0.04
n_stacked=2
dropout_LSTM=0.4
batch size=256
rnn hidden size = 64
val_loss=[0.09243843509524466, 0.2949159553732946, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9685005509932659, 0.890359116102798, 0.7834935469796547, 0.7834935469796547]
loss=[0.12163439571380615, 0.06860500939369202, 0.1719884838740094, 1.1920930376163597e-07]
acc=[0.9525318624178568, 0.975732811088562, 0.8513311453501383, 0.8139350433286031]
score test:0.30981733196412403
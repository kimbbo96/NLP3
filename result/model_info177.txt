bigram embedding size =128
learning rate=0.03
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.1078784173053014, 0.11014305332679707, 0.11787693331352624]
val_acc=[0.9613146403940712, 0.9610050866450545, 0.9582718173310392]
loss=[0.10570925348281861, 0.07530866854508718, 0.07819305488665898]
acc=[0.9626594933382671, 0.973479447148641, 0.9723080526351928]
score test:0.8662896282394362
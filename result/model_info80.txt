bigram embedding size =64
learning rate=0.04
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 64
val_loss=[0.10286206859442718, 0.11247381135127497, 0.11365669618821198]
val_acc=[0.9640464347904908, 0.9602718022868797, 0.9594309591665501]
loss=[0.09314996354818345, 0.07470571989854177, 0.07727092056671778]
acc=[0.9671106912358602, 0.9737145471127828, 0.9730293615659078]
score test:0.8705743091141789
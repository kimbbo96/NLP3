bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.07443015112184367, 0.0706740892647111, 0.07766280681753898, 0.08087976450335953]
val_acc=[0.9743678070224838, 0.9754495607511432, 0.9759675576258657, 0.976127167763044]
loss=[0.09532866891860962, 0.037581708388328555, 0.02828928372224172, 0.023150627041459083]
acc=[0.9641642449696859, 0.986470483938853, 0.9896945773188273, 0.9915099865659078]
score test:0.9238318300696576
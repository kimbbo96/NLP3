bigram embedding size =32
learning rate=0.03
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[0.7659398505005762, 0.7330615353954341, 0.722596091864643, 0.7384584564591723]
val_acc=[0.7834935469796547, 0.7834935469796547, 0.7875768686345306, 0.7875768686345306]
loss=[0.7426461519940695, 0.7044510166549682, 0.7069734470176697, 0.7069049176724752]
acc=[0.7895800464725494, 0.7921141420809428, 0.7919665807914734, 0.7918206386693318]
score test:0.3234605247848807
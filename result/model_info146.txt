bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.09263400308903463, 0.09631307058019807, 0.09747869463559]
val_acc=[0.9679296035195666, 0.9664931774403727, 0.9654584105421857]
loss=[0.09652318223953248, 0.05348513934294383, 0.050986748956839245]
acc=[0.9642829373296102, 0.9812114205932617, 0.9820484972127279]
score test:0.8894785032451272
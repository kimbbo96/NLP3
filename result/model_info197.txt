bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.3
batch size=128
rnn hidden size = 256
val_loss=[0.07440065343073361, 0.07717091854488242, 0.0780691510425703]
val_acc=[0.9738990020857682, 0.9743184103669719, 0.9759183519431069]
loss=[0.08545027808984121, 0.03486910382628441, 0.02603561161418756]
acc=[0.9690969184112549, 0.9874539787356059, 0.9905070827929179]
score test:0.9233563164896981
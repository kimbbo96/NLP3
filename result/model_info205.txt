bigram embedding size =128
learning rate=0.005
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[0.0787883932039373, 0.0825747084657263, 0.08133628158241576]
val_acc=[0.9730101041413199, 0.9733424810506817, 0.9746697213327277]
loss=[0.12814913292884828, 0.040904047068357464, 0.03154210596005122]
acc=[0.9495057038752238, 0.9855378174463908, 0.9887026462936401]
score test:0.9190412836843197
bigram embedding size =32
learning rate=0.04
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.10225955036751712, 0.11989556226524176, 0.13590766558890333]
val_acc=[0.9635234720955402, 0.957483539427992, 0.9509587886592501]
loss=[0.12023301966587703, 0.07248909095923106, 0.09505103356202443]
acc=[0.9561887582143148, 0.9747846775054931, 0.9665603164863587]
score test:0.8433941552298906
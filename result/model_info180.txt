bigram embedding size =128
learning rate=0.03
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.1056577634652808, 0.09681637628115466, 0.09960649238523517, 0.27587441687044706]
val_acc=[0.9651587033218925, 0.9679914152542927, 0.9642169130615015, 0.8946191005061841]
loss=[0.10199177408933639, 0.06167023824930191, 0.06311192833741507, 0.10313628635168076]
acc=[0.963955590763092, 0.9783689802106221, 0.9777058599662781, 0.963194017384847]
score test:0.6681370490841305
bigram embedding size =128
learning rate=0.03
n_stacked=2
dropout_LSTM=0.3
batch size=128
rnn hidden size = 256
val_loss=[0.3475380288788062, 0.24294494888734924, 0.5307768173598397, 1.1920930968545122e-07]
val_acc=[0.8385569651481053, 0.9138704254199026, 0.8683585233804656, 0.7834935469796547]
loss=[0.40097171913146973, 0.30374347354888914, 0.3996699535433451, 0.2617948449293772]
acc=[0.8010256788380941, 0.8758610323588053, 0.8950434395853678, 0.844900379447937]
score test:0.30981733196412403
bigram embedding size =64
learning rate=0.04
n_stacked=2
dropout_LSTM=0.3
batch size=128
rnn hidden size = 256
val_loss=[0.8281655106734807, 0.9471940448437456, 0.80144484886309, 0.694908372050114]
val_acc=[0.7834935469796547, 0.7869943541592347, 0.7938914063764517, 0.7875768686345306]
loss=[0.730863913491567, 0.7223586485290527, 0.7182479119491577, 0.7066346105893453]
acc=[0.7901205147679646, 0.7914382403500875, 0.7925542444864909, 0.7931728094863891]
score test:0.3234605247848807
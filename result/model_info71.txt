bigram embedding size =32
learning rate=0.005
n_stacked=2
dropout_LSTM=0.4
batch size=256
rnn hidden size = 256
val_loss=[0.08273472247062924, 0.08088002938719388, 0.08806841916295219, 0.0882440388301788]
val_acc=[0.9707443662599027, 0.9736279243904841, 0.972591609621788, 0.9726371081863961]
loss=[0.18379031323512396, 0.04087784391800563, 0.031201033462285994, 0.025316599488655726]
acc=[0.9253552019500733, 0.9855016091791788, 0.9888836223983765, 0.9909502761014303]
score test:0.9129051350407981
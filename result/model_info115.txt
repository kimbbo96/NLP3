bigram embedding size =64
learning rate=0.03
n_stacked=2
dropout_LSTM=0.3
batch size=256
rnn hidden size = 256
val_loss=[0.7108273066068171, 0.7400033603486359, 0.7412692523848455]
val_acc=[0.7875856250987084, 0.7834935469796547, 0.7834935469796547]
loss=[0.670939432442983, 0.65190494541804, 0.6541551765950521]
acc=[0.8104418802324931, 0.8137418362363179, 0.8139849194653829]
score test:0.30981733196412403
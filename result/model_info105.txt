bigram embedding size =64
learning rate=0.03
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.11036003309977292, 0.21729937512964473, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9601027960259211, 0.9160175320843107, 0.7834935469796547, 0.7834935469796547]
loss=[0.1449675830133756, 0.11042747470537821, 0.14863062601884536, 1.1920930695093071e-07]
acc=[0.9424189973322551, 0.9600097176361084, 0.8853178949673971, 0.7921658163833618]
score test:0.30981733196412403
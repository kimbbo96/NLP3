bigram embedding size =128
learning rate=0.04
n_stacked=2
dropout_LSTM=0.3
batch size=256
rnn hidden size = 256
val_loss=[0.7324998295492184, 0.8625714957317597, 0.8170229353820141]
val_acc=[0.7834935469796547, 0.7834935469796547, 0.7875768686345306]
loss=[0.7224122300020853, 0.6881464903132121, 0.683415303662618]
acc=[0.8105327386029562, 0.8140902655982971, 0.8139101090431213]
score test:0.3234605247848807
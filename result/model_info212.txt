bigram embedding size =128
learning rate=0.005
n_stacked=2
dropout_LSTM=0.4
batch size=128
rnn hidden size = 64
val_loss=[0.07937116279966816, 0.07462090465287675, 0.07811602910447808, 0.07780577896571741]
val_acc=[0.9730135300207032, 0.9752435513716315, 0.9753419286395917, 0.9756224648386834]
loss=[0.15886077750603358, 0.042001703993876774, 0.0322103726375103, 0.02653242986480395]
acc=[0.9333621245193482, 0.985097453289032, 0.9884812399419148, 0.9904496680641174]
score test:0.9216211977883559
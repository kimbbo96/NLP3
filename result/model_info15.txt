bigram embedding size =32
learning rate=0.04
n_stacked=2
dropout_LSTM=0.2
batch size=256
rnn hidden size = 256
val_loss=[0.7078733953034005, 0.7229273102500222, 0.7163387436560147]
val_acc=[0.7875768686345306, 0.7875768686345306, 0.7875768686345306]
loss=[0.7093023288154602, 0.675474792950948, 0.6804650338745117]
acc=[0.8117961671765646, 0.8136932487424214, 0.8137668722979228]
score test:0.3234605247848807
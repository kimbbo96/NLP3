bigram embedding size =64
learning rate=0.005
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.07866416926064142, 0.07330460839816048, 0.07608005430904566, 0.08390396663262416]
val_acc=[0.9728004304638459, 0.9749741201390184, 0.9752701984805172, 0.9740312729865115]
loss=[0.14875932581543921, 0.04165920310695966, 0.031923111862738926, 0.026326005214452743]
acc=[0.9381715311050415, 0.9853417631212871, 0.9885925450452169, 0.9906868169720967]
score test:0.9172049918808586
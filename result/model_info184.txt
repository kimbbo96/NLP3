bigram embedding size =128
learning rate=0.03
n_stacked=2
dropout_LSTM=0.3
batch size=128
rnn hidden size = 64
val_loss=[0.4330242202842315, 1.1920930968545122e-07, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.804754187553262, 0.7834935469796547, 0.7834935469796547, 0.7834935469796547]
loss=[0.21481957702557247, 0.07756840304694043, 1.1920930695093071e-07, 1.1920930695093071e-07]
acc=[0.9166395495669047, 0.7940917349624633, 0.7921658163833618, 0.7921658163833618]
score test:0.30981733196412403
bigram embedding size =128
learning rate=0.04
n_stacked=2
dropout_LSTM=0.2
batch size=256
rnn hidden size = 256
val_loss=[0.9376481145025621, 0.9913364247049302, 1.2640669218981082]
val_acc=[0.7875768686345306, 0.7834935469796547, 0.7834935469796547]
loss=[0.7394049179649353, 0.8269466219520569, 0.8284148752021789]
acc=[0.8100278780937195, 0.8126917987759908, 0.813923572991689]
score test:0.30981733196412403
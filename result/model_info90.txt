bigram embedding size =64
learning rate=0.04
n_stacked=2
dropout_LSTM=0.3
batch size=256
rnn hidden size = 64
val_loss=[0.12405375868676771, 1.1920930968545122e-07, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9573102170506497, 0.7834935469796547, 0.7834935469796547, 0.7834935469796547]
loss=[0.21167653584480287, 0.14155212638696388, 1.1920930376163597e-07, 1.1920930376163597e-07]
acc=[0.9115640820948283, 0.9009970134671529, 0.8139350433286031, 0.8139350433286031]
score test:0.30981733196412403
bigram embedding size =128
learning rate=0.04
n_stacked=2
dropout_LSTM=0.3
batch size=256
rnn hidden size = 64
val_loss=[0.09026647002297865, 0.09729951127801925, 0.09969428171736174]
val_acc=[0.9683729316337145, 0.9673415764736759, 0.9653028970018459]
loss=[0.10394328287442525, 0.051233106971581774, 0.04983761691013972]
acc=[0.9635314210255941, 0.9818387732378642, 0.982120363705953]
score test:0.889620145588094
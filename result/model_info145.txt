bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[0.12339524908234963, 0.12373045390831129, 0.13942823673034718]
val_acc=[0.9569401036609303, 0.9562354427483553, 0.950378311975568]
loss=[0.14719262033144634, 0.08835484127998353, 0.09272332550843557]
acc=[0.9445251732953389, 0.9691127076148986, 0.9673106097793579]
score test:0.8416438605632307
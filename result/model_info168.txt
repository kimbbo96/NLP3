bigram embedding size =128
learning rate=0.03
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.0927289271698294, 0.09802482473744521, 0.09455377706006467]
val_acc=[0.9688323285521531, 0.9668434414260932, 0.9677543770976182]
loss=[0.08772755603790283, 0.05811756739139557, 0.05649932414929072]
acc=[0.9687178899447123, 0.9795076842053732, 0.9800170128822326]
score test:0.8969602541468326
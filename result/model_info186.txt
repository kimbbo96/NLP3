bigram embedding size =128
learning rate=0.03
n_stacked=2
dropout_LSTM=0.3
batch size=256
rnn hidden size = 64
val_loss=[0.08956696170727059, 0.08825703994463922, 0.09492456381046058, 0.08915326532860289]
val_acc=[0.9693280135977295, 0.9709519877402059, 0.968615631174354, 0.9701419750232654]
loss=[0.10889325697978337, 0.04949145913640658, 0.0454045681420962, 0.04462705088376999]
acc=[0.9593447144826254, 0.9824323523139954, 0.9837359028307597, 0.9840591446749369]
score test:0.9040828405360151
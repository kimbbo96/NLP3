bigram embedding size =128
learning rate=0.04
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.110341308948206, 0.10882445287678036, 0.11671556839657464, 1.1920930968545122e-07]
val_acc=[0.960724067661556, 0.9614643725481901, 0.9589234535022744, 0.7834935469796547]
loss=[0.12011487107276916, 0.07971704186439514, 0.08265635095437368, 0.028624478101744122]
acc=[0.9566588612079621, 0.9717769541613261, 0.9708392174148559, 0.8265954740269978]
score test:0.30981733196412403
bigram embedding size =64
learning rate=0.005
n_stacked=1
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.08366214442676029, 0.07675083520142836, 0.07567448195425211, 0.08361535798551767]
val_acc=[0.971378923651913, 0.9732313844687129, 0.9752025087498244, 0.9751450748507041]
loss=[0.10956702446540197, 0.03727554899573326, 0.02840889578104019, 0.02314250231762727]
acc=[0.9582731324895223, 0.9868365577379863, 0.9897769567616781, 0.9916286338933309]
score test:0.9202199503240068
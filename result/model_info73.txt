bigram embedding size =64
learning rate=0.04
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[0.1314160535050073, 0.13276973726876296, 0.1347536077586616]
val_acc=[0.952386094434827, 0.953683672881708, 0.9514785241129129]
loss=[0.12006051488558452, 0.09089959055026373, 0.09191060048739115]
acc=[0.9566708531443278, 0.9680767598724366, 0.9675325595919291]
score test:0.8450635114148553
bigram embedding size =128
learning rate=0.005
n_stacked=2
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.08164093091654408, 0.08283741474812417, 0.07943795882413233, 0.08102483275922598]
val_acc=[0.972338191685814, 0.9715100932544193, 0.9747212484247668, 0.9749601258671204]
loss=[0.1323936643664042, 0.041833965642054875, 0.03272608167846998, 0.027417100669145582]
acc=[0.9456756071790059, 0.9851873436673483, 0.988310175704956, 0.9901301621691386]
score test:0.9199063137074377
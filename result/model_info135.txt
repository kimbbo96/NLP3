bigram embedding size =64
learning rate=0.005
n_stacked=2
dropout_LSTM=0.2
batch size=256
rnn hidden size = 256
val_loss=[0.08517848637508448, 0.07511111023420769, 0.0810177429288031, 0.08519974126255433]
val_acc=[0.9708183303376259, 0.973618108655291, 0.9728708565895944, 0.9728651077149977]
loss=[0.14191063805739085, 0.03958652432918549, 0.029988123571077982, 0.024567767047484715]
acc=[0.9443054895019531, 0.9860595350138346, 0.9891734768040975, 0.9911427842521667]
score test:0.9133705313105458
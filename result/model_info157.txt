bigram embedding size =128
learning rate=0.04
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[3.4896717055673876, 3.4896717055673876, 3.4896717055673876]
val_acc=[0.7834935469796547, 0.7834935469796547, 0.7834935469796547]
loss=[3.3454836667124432, 3.349881387354533, 3.3498874270884196]
acc=[0.7908292975234985, 0.7921658163833618, 0.7921658163833618]
score test:0.30981733196412403
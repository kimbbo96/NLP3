bigram embedding size =64
learning rate=0.005
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[0.08871497213840485, 0.07520599891235454, 0.07429418813627205, 0.07781761617063154]
val_acc=[0.9692857424065702, 0.9756929254584725, 0.9764621712416081, 0.9757550268902747]
loss=[0.12175198688109716, 0.03955636436780294, 0.029987756122350693, 0.024235307143131893]
acc=[0.9499199595896403, 0.9861344042650858, 0.9893046050071717, 0.9914003294436137]
score test:0.9224811691563681
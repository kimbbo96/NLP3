bigram embedding size =32
learning rate=0.005
n_stacked=1
dropout_LSTM=0.3
batch size=256
rnn hidden size = 64
val_loss=[0.08297829171374209, 0.0777622990293672, 0.07600024692763775, 0.0778286012009348]
val_acc=[0.9712841597999015, 0.9738519093942748, 0.9744103812589878, 0.975056010312886]
loss=[0.12723879221757253, 0.03930451357007027, 0.03093022629459699, 0.02526035837272803]
acc=[0.9508305024909973, 0.9862136414146423, 0.9890626795196533, 0.9909375707689921]
score test:0.9202806541852783
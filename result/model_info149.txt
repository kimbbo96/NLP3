bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.3
batch size=128
rnn hidden size = 256
val_loss=[0.14373780036977019, 0.14035879006142626, 0.15754453464516516, 1.1920930968545122e-07]
val_acc=[0.9479461119338837, 0.9500226398265018, 0.9424471104488669, 0.7834935469796547]
loss=[0.15711765974839528, 0.11201128303050994, 0.10688122851848603, 0.11183281336943386]
acc=[0.9406793082491557, 0.9607267120361328, 0.9624016223589579, 0.9436931734975179]
score test:0.30981733196412403
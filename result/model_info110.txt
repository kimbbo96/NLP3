bigram embedding size =64
learning rate=0.03
n_stacked=2
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.09188870499178999, 0.0987879359669273, 0.1009497555125579]
val_acc=[0.969616539991087, 0.9678826452358863, 0.9658306719458553]
loss=[0.14746973050117493, 0.05101286552429199, 0.04561387113491694]
acc=[0.94212858446757, 0.9822789693832398, 0.9839612497965495]
score test:0.8904194130948346
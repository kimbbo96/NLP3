bigram embedding size =64
learning rate=0.04
n_stacked=1
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.08961619922432826, 0.09036717441618575, 0.09287220214859081]
val_acc=[0.968930059420296, 0.9688916046444963, 0.968199923006764]
loss=[0.09059756093184153, 0.048010280016263326, 0.045622573821544644]
acc=[0.9675283273188273, 0.9830239468892416, 0.9836985709571838]
score test:0.897673524516772
bigram embedding size =64
learning rate=0.04
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.10113976385337022, 0.11254260997946669, 0.11455365602430906]
val_acc=[0.9657229535331219, 0.9613792955743236, 0.959692956999506]
loss=[0.08795108452796936, 0.07198291172345479, 0.07525738286415735]
acc=[0.9688942552312215, 0.97490699315389, 0.9737528356234233]
score test:0.8711914650371052
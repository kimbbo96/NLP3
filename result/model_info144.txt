bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.10598607582686481, 0.10738233134910431, 0.10930366318532474]
val_acc=[0.9625678983601657, 0.9632714655076849, 0.9618333504099539]
loss=[0.09057917846520742, 0.07266854361216227, 0.07467631446838378]
acc=[0.9680491678746541, 0.9745076522445679, 0.9738766009902954]
score test:0.877959945568871
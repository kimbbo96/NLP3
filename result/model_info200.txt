bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 64
val_loss=[0.08305575236050358, 0.07672222984537581, 0.08917304686788974, 0.08747206178974946]
val_acc=[0.9722348454257601, 0.9745034788241672, 0.9721545715818384, 0.9739522821623048]
loss=[0.09180835404396057, 0.03850802063902219, 0.030017035974264146, 0.02472995674530665]
acc=[0.9658917955271403, 0.9860563397661845, 0.9890132194137573, 0.9908966711425782]
score test:0.9171999332257526
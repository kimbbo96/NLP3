bigram embedding size =64
learning rate=0.04
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.10395421224858967, 1.1920930968545122e-07, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9640761420890656, 0.7834935469796547, 0.7834935469796547, 0.7834935469796547]
loss=[0.13281327644427618, 0.0754950329780616, 1.1920930695093071e-07, 1.1920930695093071e-07]
acc=[0.9501194728533426, 0.9293269794082641, 0.7921658163833618, 0.7921658163833618]
score test:0.30981733196412403
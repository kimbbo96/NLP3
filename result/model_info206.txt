bigram embedding size =128
learning rate=0.005
n_stacked=2
dropout_LSTM=0.2
batch size=256
rnn hidden size = 64
val_loss=[0.09063196677855008, 0.07976660532195394, 0.08133559875570222, 0.08580215133214472]
val_acc=[0.9693143428561428, 0.9723156350943571, 0.9730104619013497, 0.9729107854900233]
loss=[0.21427436860402424, 0.0423130700647831, 0.03023050945440928, 0.023707755838433903]
acc=[0.9050781394004822, 0.9851920904604594, 0.9891523476282755, 0.9913936649068197]
score test:0.9132845341737446
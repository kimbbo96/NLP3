bigram embedding size =64
learning rate=0.04
n_stacked=1
dropout_LSTM=0.3
batch size=128
rnn hidden size = 64
val_loss=[0.10068805593410775, 0.1073391872340454, 0.1073518125650095]
val_acc=[0.9656463190087193, 0.962452721701493, 0.9618913011910382]
loss=[0.08941764961878458, 0.06773865073919297, 0.07033692368507385]
acc=[0.9681974465243022, 0.9761597373580932, 0.9751499036916097]
score test:0.878501221665208
bigram embedding size =64
learning rate=0.03
n_stacked=2
dropout_LSTM=0.2
batch size=256
rnn hidden size = 256
val_loss=[0.3678528089613185, 0.9225332452822683, 0.6881506942592545]
val_acc=[0.8220044221159095, 0.7834935469796547, 0.787634473946565]
loss=[0.4044358117993673, 0.49476818403244016, 0.6404221676699321]
acc=[0.8191465661811829, 0.8226487597084046, 0.8141621773211162]
score test:0.32361734309316526
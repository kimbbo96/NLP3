bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.3
batch size=128
rnn hidden size = 64
val_loss=[0.1033992938317375, 0.10822367228716281, 0.11338713927041665]
val_acc=[0.9632745046837631, 0.9614544428901504, 0.9620176781043245]
loss=[0.09383506297270457, 0.07214021510680517, 0.07411310796499253]
acc=[0.9669462752469381, 0.9746011070124309, 0.973933349278768]
score test:0.8784202831835128
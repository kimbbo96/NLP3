bigram embedding size =32
learning rate=0.005
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.07497584444786651, 0.0743133521198962, 0.07655561543555059, 0.08343189936585543]
val_acc=[0.9740755643918615, 0.97457479690501, 0.9755986009098738, 0.9728798124848342]
loss=[0.09717389359196027, 0.03944754581093788, 0.03044125396410624, 0.02493652316192786]
acc=[0.963610557346344, 0.9859326414553324, 0.9889581135749816, 0.9908855762926737]
score test:0.9137398131332803
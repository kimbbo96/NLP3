bigram embedding size =32
learning rate=0.04
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 64
val_loss=[0.10208217479172937, 0.10444366129036753, 0.11116950412150761]
val_acc=[0.9646463926774171, 0.9637870292970188, 0.9608033251868119]
loss=[0.08737291344086329, 0.0695466747132937, 0.07152715627829234]
acc=[0.9691653753344218, 0.9755328509076436, 0.9748373371060689]
score test:0.874262068686419
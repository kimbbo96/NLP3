bigram embedding size =64
learning rate=0.03
n_stacked=2
dropout_LSTM=0.2
batch size=128
rnn hidden size = 64
val_loss=[0.09662262867401021, 0.09378654876529774, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9681503948509825, 0.9677343931536453, 0.7834935469796547, 0.7834935469796547]
loss=[0.13952618120511373, 0.05702652825276057, 0.0507904856141507, 1.1920930695093071e-07]
acc=[0.94290107503891, 0.9799968527984619, 0.8638375979105631, 0.7921658163833618]
score test:0.30981733196412403
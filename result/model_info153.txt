bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.11394163480486943, 0.1269185539756276, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.95963976798195, 0.9557293048190436, 0.7834935469796547, 0.7834935469796547]
loss=[0.12323471939722697, 0.08499855041583379, 0.08892934103807139, 1.1920930695093071e-07]
acc=[0.9543333261617025, 0.9702749694188436, 0.9298700382868449, 0.7921658163833618]
score test:0.30981733196412403
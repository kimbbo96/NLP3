bigram embedding size =128
learning rate=0.04
n_stacked=1
dropout_LSTM=0.4
batch size=128
rnn hidden size = 64
val_loss=[0.10462339445452996, 0.10647359919918085, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9635098203851484, 0.9617684015677932, 0.7834935469796547, 0.7834935469796547]
loss=[0.09661919660568237, 0.07386019793987274, 0.1117829609974271, 1.1920930695093071e-07]
acc=[0.9653197519938151, 0.973837371228536, 0.8701144466718038, 0.7921658163833618]
score test:0.30981733196412403
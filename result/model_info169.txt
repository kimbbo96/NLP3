bigram embedding size =128
learning rate=0.03
n_stacked=1
dropout_LSTM=0.2
batch size=128
rnn hidden size = 256
val_loss=[0.10384883006369725, 0.14408912693053286, 0.11967860988264867]
val_acc=[0.9642167162736609, 0.9464066536093498, 0.9575890897382918]
loss=[0.11850785441239675, 0.06265720557928085, 0.06849435439745585]
acc=[0.9567654556210836, 0.9781204377937317, 0.9760996330006917]
score test:0.8646303893646835
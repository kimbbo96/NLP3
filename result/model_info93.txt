bigram embedding size =64
learning rate=0.04
n_stacked=2
dropout_LSTM=0.4
batch size=128
rnn hidden size = 256
val_loss=[0.7381655959755248, 0.7361141831806124, 0.7250788856768555, 0.9346855262959347]
val_acc=[0.7875768686345306, 0.7875768686345306, 0.7875768686345306, 0.7875768686345306]
loss=[0.7598648437245686, 0.7326841804695129, 0.7290257002067566, 0.785136835085551]
acc=[0.7896720210711161, 0.7913753245989482, 0.7913251804097493, 0.7918695352490743]
score test:0.3234605247848807
bigram embedding size =32
learning rate=0.03
n_stacked=2
dropout_LSTM=0.4
batch size=256
rnn hidden size = 64
val_loss=[0.09197904805584652, 0.09093920427256835, 1.1920930968545122e-07, 1.1920930968545122e-07]
val_acc=[0.9703691932155922, 0.968653698321721, 0.7834935469796547, 0.7834935469796547]
loss=[0.12836935463746388, 0.04831471741199493, 0.06924686400493046, 1.1920930376163597e-07]
acc=[0.9496673600069682, 0.9828861919085184, 0.9663412486394246, 0.8139350433286031]
score test:0.30981733196412403
bigram embedding size =128
learning rate=0.005
n_stacked=1
dropout_LSTM=0.4
batch size=256
rnn hidden size = 64
val_loss=[0.08570306910049096, 0.07663527309498079, 0.07559883141861258, 0.08022091134622726]
val_acc=[0.9710939736694032, 0.9738941102757422, 0.9750806209517688, 0.9756312528893583]
loss=[0.1161765293264389, 0.03796362798810005, 0.0289317928647995, 0.023636415963570277]
acc=[0.9569989176241557, 0.9866599545160929, 0.9896507972462972, 0.991412004852295]
score test:0.9218791891987597